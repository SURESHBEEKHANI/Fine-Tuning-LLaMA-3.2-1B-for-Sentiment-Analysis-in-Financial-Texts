{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Fine-Tuning-LLaMA-3.2-1B-for-Sentiment-Analysis-in-Financial-Texts/blob/main/SURESHBEEKHANI_finance_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqM-T1RTzY6C"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth?tab=readme-ov-file#-installation-instructions).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "Features in the notebook:\n",
        "1. Uses Maxime Labonne's [FineTome 100K](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset.\n",
        "1. Convert ShareGPT to HuggingFace format via `standardize_sharegpt`\n",
        "2. Train on Completions / Assistant only via `train_on_responses_only`\n",
        "3. Unsloth now supports Torch 2.4, all TRL & Xformers versions & Python 3.12!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# The `%%capture` magic command suppresses the output (including logs and warnings) of the following cell.\n",
        "# This is useful when you don't want the installation messages cluttering your notebook's output.\n",
        "\n",
        "# Install the unsloth package from the Python Package Index (PyPI).\n",
        "!pip install unsloth\n",
        "\n",
        "# Uninstall any previously installed version of the unsloth package (-y auto-confirms the uninstallation)\n",
        "# Then, install the latest version of unsloth directly from the GitHub repository.\n",
        "# We're also installing the optional `colab-new` dependencies.\n",
        "# The `--no-cache-dir` flag avoids using cached versions of the package, ensuring the latest version is fetched.\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2v_X2fA0Df5"
      },
      "source": [
        "* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n",
        "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
        "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
        "* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n",
        "* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Necessary Libraries\n",
        "\n",
        "This code prepares a pre-trained LLaMA model using 4-bit quantization, allowing efficient memory usage. It leverages PyTorch to check the GPU’s compute capabilities and uses FastLanguageModel from the unsloth library to load the model and tokenizer, with specific configurations for sequence length and data type precision."
      ],
      "metadata": {
        "id": "KACEcaiUEu63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "5286fdb5-6f9d-4e48-c892-08ae8742567b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major: 7, Minor: 5\n",
            "==((====))==  Unsloth 2024.9.post4: Fast Llama patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Get the CUDA device capability (major and minor version).\n",
        "# This function returns the compute capability of the GPU, which indicates\n",
        "# the GPU's compatibility with certain operations or precision levels.\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
        "\n",
        "# Import necessary modules from the datasets library.\n",
        "# 'load_dataset' is used to load datasets for training or evaluation.\n",
        "from datasets import load_dataset\n",
        "import datasets\n",
        "\n",
        "# Import SFTTrainer from the 'trl' package (used for supervised fine-tuning of models).\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# Importing other common libraries used for data manipulation, model training, and evaluation.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Importing the train_test_split function from scikit-learn for splitting data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing Hugging Face's datasets library for loading datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Import FastLanguageModel from the 'unsloth' library (which is likely a wrapper around language models).\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Importing additional modules for handling training.\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from typing import Tuple, Any, Dict, List, Union\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Set maximum sequence length for the model inputs.\n",
        "# RoPE (Rotary Positional Embedding) Scaling allows you to extend the sequence length for transformer models.\n",
        "max_seq_length = 2048  # Maximum sequence length. Adjust based on your model's needs.\n",
        "\n",
        "# Set the data type (precision) for model computation.\n",
        "# 'None' for auto detection, 'float16' for Tesla T4 and V100, 'bfloat16' for Ampere and newer GPUs.\n",
        "dtype = None  # Default is auto-detection based on the GPU hardware.\n",
        "\n",
        "# Define the model name and whether to load the model in 4-bit precision.\n",
        "# 'bnb-4bit' refers to a 4-bit quantized model for efficient memory usage.\n",
        "# You can switch to different models based on your requirements.\n",
        "# Example: Uncomment the line below for the 'Qwen2-7B-bnb-4bit' model\n",
        "# model_name = \"unsloth/Qwen2-7B-bnb-4bit\"; load_in_4bit = True\n",
        "model_name = \"unsloth/llama-3.2-1b-bnb-4bit\"  # Set to use the 1B parameter LLaMA model with 4-bit quantization.\n",
        "load_in_4bit = True  # Load the model using 4-bit precision to save memory.\n",
        "\n",
        "# Load the pre-trained model and tokenizer using FastLanguageModel from the unsloth library.\n",
        "# 'max_seq_length' is passed to ensure the model supports the desired input sequence length.\n",
        "# 'dtype' is used to define the precision in which the model should operate.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,        # Specify the model name.\n",
        "    load_in_4bit=load_in_4bit,    # Whether to load the model in 4-bit precision.\n",
        "    max_seq_length=max_seq_length,  # The maximum sequence length for the model's inputs.\n",
        "    dtype=dtype,                  # The precision type for the model (auto-detected if None).\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Apply Parameter-Efficient Fine-Tuning (PEFT) to the Model\n",
        "\n",
        "This code applies PEFT (Parameter-Efficient Fine-Tuning) using LoRA (Low-Rank Adaptation) to a pre-trained model. It specifies which model layers will be fine-tuned and includes several optimizations, such as using gradient checkpointing to reduce VRAM usage. The process is configured for a balance between model adaptability and memory efficiency."
      ],
      "metadata": {
        "id": "upMJZSwkFGEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "# Apply Parameter-Efficient Fine-Tuning (PEFT) to the loaded model using the FastLanguageModel API.\n",
        "# PEFT allows fine-tuning large models by training only a few additional parameters while keeping the original model frozen.\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,  # The pre-trained model loaded earlier.\n",
        "\n",
        "    # Rank of the low-rank decomposition matrices for LoRA (Low-Rank Adaptation).\n",
        "    # Higher values increase model capacity but also VRAM usage.\n",
        "    # Suggested values are 8, 16, 32, 64, 128 based on the model size and task complexity.\n",
        "    r=16,\n",
        "\n",
        "    # Specifies the modules within the model that will use LoRA fine-tuning.\n",
        "    # These typically include projection layers in attention and feedforward blocks.\n",
        "    target_modules=[\n",
        "        \"q_proj\",  # Query projection in attention heads.\n",
        "        \"k_proj\",  # Key projection in attention heads.\n",
        "        \"v_proj\",  # Value projection in attention heads.\n",
        "        \"o_proj\",  # Output projection in attention heads.\n",
        "        \"gate_proj\",  # Gate projection in feed-forward blocks.\n",
        "        \"up_proj\",   # Up projection in feed-forward blocks.\n",
        "        \"down_proj\", # Down projection in feed-forward blocks.\n",
        "    ],\n",
        "\n",
        "    # LoRA alpha is a scaling factor applied to the LoRA weights.\n",
        "    # Increasing this value allows LoRA to affect the model's behavior more strongly.\n",
        "    lora_alpha=16,\n",
        "\n",
        "    # LoRA dropout rate. A value of 0 means no dropout, which is optimized for performance.\n",
        "    # Dropout helps with regularization, but can be set to 0 when working with optimized training setups.\n",
        "    lora_dropout=0,\n",
        "\n",
        "    # Specifies how biases should be handled. \"none\" means no bias parameters are added to the LoRA layers.\n",
        "    # This is the most optimized option in terms of memory and computation.\n",
        "    bias=\"none\",\n",
        "\n",
        "    # [NEW] Unsloth optimizes VRAM usage by 30%, allowing for larger batch sizes during training.\n",
        "    # \"unsloth\" option allows for highly optimized gradient checkpointing.\n",
        "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" enables this for very long sequences.\n",
        "\n",
        "    # Sets a random state for reproducibility in the fine-tuning process.\n",
        "    random_state=3407,\n",
        "\n",
        "    # Option to use Rank Stabilized LoRA (RSLoRA) for more stable fine-tuning in certain setups.\n",
        "    # In this case, it's disabled.\n",
        "    use_rslora=False,  # Rank Stabilized LoRA is not used.\n",
        "\n",
        "    # Optional configuration for LoFTQ (Low-Frequency Tensor Quantization), which optimizes further\n",
        "    # for memory and inference speed. None means it is not being used in this setup.\n",
        "    loftq_config=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset and  Preparation\n",
        "\n",
        "This code effectively loads a financial sentiment dataset from Hugging Face, samples a controlled subset, and splits it into training and validation sets, making it suitable for further model training and evaluation."
      ],
      "metadata": {
        "id": "EBVns7k2GQBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the train_test_split function from scikit-learn for splitting data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing Hugging Face's datasets library for loading datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset from Hugging Face Hub\n",
        "# \"SURESHBEEKHANI/finance_sentiment\" is the name of the dataset, and \"train\" is the specific split being loaded.\n",
        "# If no split is specified, \"train\" is usually the default, but here it is specified explicitly.\n",
        "dataset = load_dataset(\"SURESHBEEKHANI/finance_sentiment\", split=\"train\")\n",
        "\n",
        "# Convert Hugging Face dataset to a Pandas DataFrame.\n",
        "# Hugging Face datasets come in their own format, but for many operations (like sampling, or data analysis),\n",
        "# it's easier to work with the Pandas DataFrame format.\n",
        "data = pd.DataFrame(dataset)\n",
        "\n",
        "# Define the sizes for the training and validation datasets.\n",
        "# Here, we're setting the training set size to 1000 and validation set size to 1000.\n",
        "train_size = 1000\n",
        "val_size = 1000\n",
        "\n",
        "# Sample a subset from the entire dataset that is equal to the combined size of training and validation sets.\n",
        "# This random sampling is necessary to avoid using the full dataset, which could be much larger.\n",
        "# random_state=42 ensures that the random selection is reproducible.\n",
        "data_sample = data.sample(n=train_size + val_size, random_state=42)\n",
        "\n",
        "# Split the sampled data into training and validation sets using the train_test_split function.\n",
        "# test_size parameter determines the fraction of the data that will be allocated to the validation set.\n",
        "# The ratio of validation to total data (val_size / (train_size + val_size)) is used here to ensure the split is correct.\n",
        "train_df, val_df = train_test_split(data_sample, test_size=val_size / (train_size + val_size), random_state=42)\n",
        "\n",
        "# Output the lengths of the training and validation sets to confirm the split.\n",
        "print(f\"Training Set Size: {len(train_df)}\")\n",
        "print(f\"Validation Set Size: {len(val_df)}\")\n"
      ],
      "metadata": {
        "id": "0OrQyf8SA8sa",
        "outputId": "2e393d8e-f4fd-4243-e869-b84d534940cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size: 1000\n",
            "Validation Set Size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing Token Counts in Financial Sentiment Analysis Data\n",
        "\n",
        "Token Count Calculation:\n",
        "This line creates a list, token_counts, that counts the number of tokens for each text entry in the training DataFrame train_df using tokenizer.encode(x).\n",
        "\n",
        "Histogram Plotting:\n",
        "The plt.hist() function generates a histogram of the token counts with 30 bins, visualizing the distribution of token lengths in the dataset."
      ],
      "metadata": {
        "id": "05LpYSamG8TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of tokens for each text entry in the training dataset.\n",
        "# This uses the tokenizer's encode method to convert text into tokens and\n",
        "# len() to count the number of tokens.\n",
        "token_counts = [len(tokenizer.encode(x)) for x in train_df.text]\n",
        "\n",
        "# Plot a histogram of the token counts.\n",
        "# The histogram displays the distribution of token counts across all text entries.\n",
        "# 'bins=30' specifies the number of bins for the histogram.\n",
        "a = plt.hist(token_counts, bins=30)\n"
      ],
      "metadata": {
        "id": "xHzAMS0ZBTyv",
        "outputId": "3d148f9a-a24f-4119-f35c-762926d58fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Creating a Dataset for Training from a Pandas DataFrame\n",
        " This line converts the Pandas DataFrame train_df into a Hugging Face Dataset. The preserve_index=False argument indicates that the original DataFrame index will not be included in the new dataset."
      ],
      "metadata": {
        "id": "ixtqxPvBHRWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Hugging Face Dataset from the training DataFrame 'train_df'.\n",
        "# 'preserve_index=False' means the original index of the DataFrame will not be kept in the new dataset.\n",
        "train_dataset = datasets.Dataset.from_pandas(train_df, preserve_index=False)\n",
        "\n",
        "# Display the newly created dataset.\n",
        "train_dataset\n"
      ],
      "metadata": {
        "id": "O-rbZiBsBepQ",
        "outputId": "eeece1e0-0839-45c3-a793-dd5b191c9bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting Prompts for Financial Sentiment Analysis\n",
        "\n",
        "### Prompt Template Definition:\n",
        "\n",
        "A multi-line string prompt is defined, which serves as a template for sentiment analysis of financial tweets. It includes placeholders for the tweet text and expected sentiment labels.\n",
        "\n",
        "### Label Definitions:\n",
        "\n",
        "Variables positivelabel and negativelabel are assigned string values that represent positive and negative sentiments, respectively.\n",
        "\n",
        "### Function Definition:\n",
        "\n",
        "The formatting_prompts_func function takes a dataset as input and processes each tweet to format it according to the defined prompt. It checks for model compatibility and returns a list of formatted prompts.\n",
        "\n",
        "### Model Compatibility Handling:\n",
        "\n",
        "If the input dataset contains only a single string, the function checks the model name to handle specific cases (like QWEN or LLaMA models) and returns appropriate outputs.\n",
        "\n",
        "### Prompt Formatting:\n",
        "\n",
        "The function iterates through each tweet in the dataset, retrieves the corresponding sentiment label, and formats the prompt using the tweet text and label.\n",
        "\n",
        "### Return Formatted Prompts:\n",
        "\n",
        "The formatted prompts are collected in a list and returned at the end of the function."
      ],
      "metadata": {
        "id": "147Ax2BrHlpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "# Define a prompt template for analyzing the sentiment of financial tweets.\n",
        "prompt = \"\"\"Here is a financial tweet:\n",
        "{}\n",
        "\n",
        "Does this tweet have a positive sentiment? Answer with \"{}\" for positive and \"{}\" for negative.\n",
        "\n",
        "SOLUTION\n",
        "The correct answer is: \"{}\"\n",
        "\"\"\"\n",
        "\n",
        "# Define labels for positive and negative sentiments.\n",
        "positivelabel = \"Yes\"\n",
        "negativelabel = \"No\"\n",
        "\n",
        "# Function to format prompts for a dataset containing financial tweets.\n",
        "def formatting_prompts_func(dataset_):\n",
        "    # Ensure compatibility with specific transformer models (optional).\n",
        "    if isinstance(dataset_['text'], str):\n",
        "        model_name_lower = model_name.lower()\n",
        "\n",
        "        if \"qwen\" in model_name_lower:\n",
        "            return [\"\"] * 100  # QWEN model specific behavior\n",
        "        elif \"llama\" in model_name_lower:\n",
        "            return \" \"  # LLaMA model specific behavior\n",
        "        else:\n",
        "            return \" \"  # Default behavior\n",
        "\n",
        "    # Process dataset and format prompts.\n",
        "    texts = []\n",
        "    for i in range(len(dataset_['text'])):\n",
        "        t = dataset_['text'][i]  # Extract the tweet text.\n",
        "        label = positivelabel if dataset_['label'][i] == 1 else negativelabel  # Determine the label.\n",
        "\n",
        "        # Format the prompt for each text and corresponding label.\n",
        "        formatted_text = prompt.format(t, positivelabel, negativelabel, label)\n",
        "        texts.append(formatted_text)  # Append the formatted prompt to the list.\n",
        "\n",
        "    return texts  # Return the list of formatted prompts.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and print the text of the 5th entry in the dataset\n",
        "fifth_entry_text = dataset[5][\"text\"]\n",
        "print(fifth_entry_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "080ef627-13ab-495c-91b1-bd695eb6ceb0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hedge Funds Are Warming Up To Eldorado Gold Corp (EGO) Again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Data Collator for Last Token Language Modeling\n",
        "\n",
        "This custom collator is particularly useful for tasks where only the last token of the sequence needs to be considered for labeling, such as binary classification tasks. By modifying the label structure and ensuring that only relevant labels are trained on, the model can effectively learn from the input sequence"
      ],
      "metadata": {
        "id": "aYXvCfHgJoie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the positive and negative labels\n",
        "positivelabel = \"Yes\"\n",
        "negativelabel = \"No\"\n",
        "\n",
        "# Get the token IDs for \"Yes\" and \"No\"\n",
        "yes_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(positivelabel))[0]\n",
        "no_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(negativelabel))[0]\n",
        "\n",
        "# Update the DataCollatorForLastTokenLM class\n",
        "class DataCollatorForLastTokenLM(DataCollatorForLanguageModeling):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *args,\n",
        "        mlm: bool = False,\n",
        "        ignore_index: int = -100,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, mlm=mlm, **kwargs)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        batch = super().torch_call(examples)\n",
        "\n",
        "        for i in range(len(examples)):\n",
        "            # Find the last non-padding token\n",
        "            last_token_idx = (batch[\"labels\"][i] != self.ignore_index).nonzero()[-1].item()\n",
        "            # Set all labels to ignore_index except for the last token\n",
        "            batch[\"labels\"][i, :last_token_idx] = self.ignore_index\n",
        "            # The old labels for the Yes and No tokens need to be mapped to 1 and 0\n",
        "            batch[\"labels\"][i, last_token_idx] = 1 if batch[\"labels\"][i, last_token_idx] == yes_token_id else 0\n",
        "\n",
        "        return batch\n",
        "\n",
        "# Re-initialize the collator with the tokenizer\n",
        "collator = DataCollatorForLastTokenLM(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "MZGX7jPtCcI4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up the Trainer for Supervised Fine-Tuning of a Language Model\n",
        "\n",
        "This code initializes the SFTTrainer, setting up everything needed to fine-tune the model on the financial sentiment dataset effectively. Adjusting the training arguments allows customization of how the model learns, which can greatly influence performance."
      ],
      "metadata": {
        "id": "jNeqk8z-J8AX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6322d2f463f246be8cbb17ae65e758ba",
            "813b8cef26114e9ba6fb6561dca7986d",
            "db8aa1a95fd446e784ca4d26c1196434",
            "7961bc4d6ccf4bf1ae569a660638ae89",
            "ecb6a41d168e48fe8fc3246cb9625c80",
            "cf63495a03a340dab1041f573761767d",
            "0ab3c939bb5d4c18a783d0d4d1bd6686",
            "6cec4c585e6e49c1a0283a970bf48b59",
            "08c55a05776848a6a11c4b9f91f7eb4e",
            "e6212cbc05374cb494696fad01563246",
            "a005e3e2fdf1478d81b0bf8ae64cd289"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "6b32e521-208a-41b1-f1fb-fe8b84b18ac2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6322d2f463f246be8cbb17ae65e758ba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Title: Initialize the Trainer for Supervised Fine-Tuning\n",
        "# Create an instance of SFTTrainer for fine-tuning the language model on the training dataset\n",
        "trainer = SFTTrainer(\n",
        "    model=model,  # The pre-trained language model to be fine-tuned\n",
        "    tokenizer=tokenizer,  # The tokenizer used to encode input text for the model\n",
        "    train_dataset=train_dataset,  # The training dataset prepared earlier\n",
        "    max_seq_length=max_seq_length,  # Maximum sequence length for model inputs\n",
        "    dataset_num_proc=2,  # Number of processes for loading the dataset (speeding up data loading)\n",
        "    packing=False,  # Not needed because group_by_length is True (whether to pack sequences)\n",
        "\n",
        "    # Title: Specify Training Arguments\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=32,  # Batch size per device (GPU) during training\n",
        "        gradient_accumulation_steps=1,  # Number of steps to accumulate gradients before updating model weights\n",
        "        warmup_steps=10,  # Number of warmup steps for learning rate scheduler\n",
        "        learning_rate=1e-4,  # Initial learning rate for the optimizer\n",
        "        fp16=not torch.cuda.is_bf16_supported(),  # Use mixed precision training if bf16 is not supported\n",
        "        bf16=torch.cuda.is_bf16_supported(),  # Use bf16 precision if supported by the GPU\n",
        "        logging_steps=1,  # Log training progress every 1 step\n",
        "        optim=\"adamw_8bit\",  # Optimizer to use; here, AdamW with 8-bit precision is specified\n",
        "        weight_decay=0.01,  # Weight decay for regularization (L2 penalty)\n",
        "        lr_scheduler_type=\"cosine\",  # Learning rate scheduler type (cosine decay)\n",
        "        seed=3407,  # Seed for random number generators to ensure reproducibility\n",
        "        output_dir=\"outputs\",  # Directory where the model outputs (checkpoints) will be saved\n",
        "        num_train_epochs=1,  # Number of training epochs (full passes over the training dataset)\n",
        "        # report_to=\"wandb\",  # Uncomment to log training metrics to Weights and Biases\n",
        "        report_to=\"none\",  # Specify where to report training metrics; 'none' means no logging\n",
        "        group_by_length=True,  # Group sequences of similar lengths for better efficiency in training\n",
        "    ),\n",
        "\n",
        "    # Title: Specify Formatting Function for Prompts\n",
        "    formatting_func=formatting_prompts_func,  # Function to format prompts for each input text\n",
        "    data_collator=collator,  # Custom data collator to process batches of data during training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show current memory stats\n",
        "\n",
        "# Retrieve the properties of the GPU device with ID 0 (usually the first GPU).\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "\n",
        "# Calculate the maximum GPU memory reserved so far, converting it to GB for easier readability.\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "\n",
        "# Calculate the total memory of the GPU, converting it to GB.\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "\n",
        "# Print the name of the GPU and its total memory capacity in GB.\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "\n",
        "# Print the amount of memory currently reserved (used) in GB.\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")\n"
      ],
      "metadata": {
        "id": "2SYXvgStEKQW",
        "outputId": "4db02ef5-f1e2-4b25-b83f-b83823afb370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "4.84 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "ZyvwEl6qLeWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the training process and store the training statistics\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "# Retrieve the training time from the trainer's metrics\n",
        "training_time = trainer_stats.metrics['train_runtime']  # In seconds\n",
        "training_loss = trainer_stats.metrics['train_loss']  # Retrieve training loss\n",
        "\n",
        "# Print the training time and loss\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "print(f\"Training Time: {round(training_time / 60, 2)} minutes\")  # Convert to minutes\n",
        "print(f\"Final Training Loss: {training_loss}\")\n"
      ],
      "metadata": {
        "id": "S0hEHpBPEOnJ",
        "outputId": "102a531d-b30f-4ad3-d416-646c585ff07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 32 | Total steps = 32\n",
            " \"-____-\"     Number of trainable parameters = 11,272,192\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.832700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.951900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6.550100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>6.418400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.888200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5.269200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.334700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.117000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.438200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.833100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.423100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.317000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.108900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.048800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.021200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 24.4948 seconds\n",
            "Training Time: 0.41 minutes\n",
            "Final Training Loss: 1.8263876158744097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show final memory and time stats after training\n",
        "# Get the maximum memory reserved during training\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)  # Convert bytes to GB\n",
        "# Calculate the memory used specifically for LoRA training\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "# Calculate the percentage of total memory used\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "# Calculate the percentage of memory used for LoRA training\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "\n",
        "# Display the training time metrics\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "\n",
        "# Display memory usage statistics\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training (LoRA) = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory percentage of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training (LoRA) percentage of max memory = {lora_percentage} %.\")\n"
      ],
      "metadata": {
        "id": "RwW5LifiHLS1",
        "outputId": "7ada422e-c38c-4bb8-eae0-7e22b2edff13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.4948 seconds used for training.\n",
            "0.41 minutes used for training.\n",
            "Peak reserved memory = 8.824 GB.\n",
            "Peak reserved memory for training (LoRA) = 3.984 GB.\n",
            "Peak reserved memory percentage of max memory = 59.832 %.\n",
            "Peak reserved memory for training (LoRA) percentage of max memory = 27.014 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize the model for inference using FastLanguageModel's for_inference method.\n",
        "# This enables native optimizations that can result in up to 2x faster inference times.\n",
        "FastLanguageModel.for_inference(model)  # This line activates the inference optimizations for the model.\n"
      ],
      "metadata": {
        "id": "DHK8nBvPHacN",
        "outputId": "aadf6f32-5414-4fef-f28e-b366077c444d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-15): 16 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-15): 16 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a name for the saved model based on the model name.\n",
        "# The model name is modified to replace any '/' characters with '_' to ensure a valid file name.\n",
        "saved_name = f\"lora_model_{model_name.replace('/', '_')}\"\n",
        "\n",
        "# Save the trained model to the specified directory.\n",
        "# The 'save_pretrained' method stores the model's configuration and weights in a directory\n",
        "# named according to 'saved_name', allowing for easy reloading later.\n",
        "model.save_pretrained(saved_name)\n"
      ],
      "metadata": {
        "id": "yMPGqFerHf3-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from collections import defaultdict  # For grouping data by token length\n",
        "import torch.nn.functional as F  # For applying softmax and other functions\n",
        "from tqdm import tqdm  # For showing progress bars in loops\n",
        "\n",
        "# Define the prompt format for the model input\n",
        "# Adjust this according to your needs. It should have placeholders for text and label.\n",
        "prompt = \"Text: {} Label: {}\"\n",
        "\n",
        "# Step 1: Tokenize the inputs and sort them by their tokenized length\n",
        "tokenized_inputs = []  # List to hold tokenized inputs\n",
        "\n",
        "# Loop through each text in the validation DataFrame\n",
        "for i in range(len(val_df['text'])):\n",
        "    text = val_df['text'].iloc[i]  # Get the text\n",
        "    label = val_df['label'].iloc[i]  # Get the corresponding label\n",
        "    test_str = prompt.format(text, label)  # Format the string for the model\n",
        "    tokenized_input = tokenizer(test_str, return_tensors=\"pt\", add_special_tokens=False)  # Tokenize the input\n",
        "    tokenized_inputs.append((tokenized_input, test_str, label))  # Append the tokenized input and its string\n",
        "\n",
        "# Sort tokenized inputs by their tokenized length (number of tokens)\n",
        "tokenized_inputs.sort(key=lambda x: x[0]['input_ids'].shape[1])\n",
        "\n",
        "# Step 2: Group the inputs by their tokenized length\n",
        "grouped_inputs = defaultdict(list)  # Dictionary to group inputs by length\n",
        "for tokenized_input, test_str, label in tokenized_inputs:\n",
        "    length = tokenized_input['input_ids'].shape[1]  # Get the length of the input\n",
        "    grouped_inputs[length].append((tokenized_input, test_str, label))  # Group by length\n",
        "\n",
        "# Step 3: Process each group in batches of 64\n",
        "batch_size = 64  # Set the batch size\n",
        "all_outputs = []  # List to store predictions\n",
        "all_strings = []  # List to store input strings\n",
        "all_labels = []  # List to store true labels\n",
        "\n",
        "# Iterate through each group of inputs\n",
        "for length, group in tqdm(grouped_inputs.items()):  # Progress bar for each group\n",
        "    for i in range(0, len(group), batch_size):  # Process in batches\n",
        "        batch = group[i:i + batch_size]  # Get the current batch\n",
        "        batch_inputs = [item[0] for item in batch]  # Extract tokenized inputs\n",
        "        batch_strings = [item[1] for item in batch]  # Extract original strings\n",
        "        batch_labels = [item[2] for item in batch]  # Extract labels\n",
        "\n",
        "        # Concatenate the batch inputs into tensors\n",
        "        input_ids = torch.cat([item['input_ids'] for item in batch_inputs], dim=0).to(\"cuda\")  # Move to GPU\n",
        "        attention_mask = torch.cat([item['attention_mask'] for item in batch_inputs], dim=0).to(\"cuda\")  # Move to GPU\n",
        "\n",
        "        # Forward pass through the model\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # Get model outputs\n",
        "            # Extract logits for the last token (assuming binary classification)\n",
        "            logits = outputs.logits[:, -1, :2]  # Logits for classes 0 and 1\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Get predicted class\n",
        "            predictions = torch.argmax(probabilities, dim=-1)\n",
        "\n",
        "            # Store results for later analysis\n",
        "            all_outputs.extend(predictions.cpu().numpy())  # Store predictions\n",
        "            all_labels.extend(batch_labels)  # Store true labels\n",
        "            all_strings.extend(batch_strings)  # Store input strings\n",
        "\n",
        "# Step 4: Calculate accuracy and display results\n",
        "correct = 0  # Counter for correct predictions\n",
        "total = 0  # Total number of predictions\n",
        "\n",
        "# Loop through all outputs to evaluate performance\n",
        "for i in range(len(all_outputs)):\n",
        "    pred = str(all_outputs[i])  # Convert prediction to string\n",
        "    label = str(all_labels[i])  # Convert true label to string\n",
        "\n",
        "    # Print the last 25 predictions along with their corresponding input strings\n",
        "    if i > len(all_outputs) - 25:\n",
        "        print(f\"{i}: text: {all_strings[i]}\\n pred: {pred} label: {label}\\n\")\n",
        "\n",
        "    # Count correct predictions\n",
        "    if pred == label:\n",
        "        correct += 1  # Increment if prediction matches the label\n",
        "    total += 1  # Increment total count\n",
        "\n",
        "# Print accuracy results\n",
        "print(f\"Correct: {correct} Total: {total} Accuracy: {correct/total:.2f}\")\n"
      ],
      "metadata": {
        "id": "Aizq7JIOHqtW",
        "outputId": "0c1484f1-0eaf-4768-dd42-29cc792e58d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:07<00:00,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "976: text: Text: Ban on flavored vapes could lead to loss of 150,000 jobs, $8.4 billion sales hit: report https://t.co/rBpi75OKM5 https://t.co/oXLLryarER Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "977: text: Text: Home Depot stock is still a good investment despite rare misstep: analysts https://t.co/qlN2H3v7I4 by @BrianSozzi https://t.co/SxTiA8QZoZ Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "978: text: Text: McDonald's could be the key to $1 billion in sales for Beyond Meat, UBS says https://t.co/Yszf0Gfz93 by @heidi_chung https://t.co/ToTuDKhmBI Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "979: text: Text: Swedish gearmaker Ericsson expects 2.6 billion 5G subscriptions by end of 2025 https://t.co/WLnBwVZiaq https://t.co/3vB1JqvJ2L Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "980: text: Text: $BGR - BlackRock Energy & Resources Trust: Buy This 8.3% Yielding CEF For Upside In Oil. Read more and get updates… https://t.co/ucVW2s05J1 Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "981: text: Text: U.S. Stocks Open Higher as Risk Appetite Improves #SP500 #index #MarketScreener https://t.co/NXv3PaJHsD https://t.co/yxgg3k0IBu Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "982: text: Text: NVIDIA : Shares up 5%; Morgan Stanley Upgrades to Overweight #NVIDIA #Stock #MarketScreener https://t.co/YeynnTYOiH https://t.co/Le1UySQ7qW Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "983: text: Text: Wall St. volatility raises fears of another selloff #Samp;P500 #economy #MarketScreener https://t.co/j4Jebb8qvW https://t.co/itcItsWEb1 Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "984: text: Text: $NVDA (+2.6% pre) Morgan Stanley Upgrades NVIDIA (NVDA) to Overweight, Sees Gaming/Data Center Accelerating in 2020… https://t.co/8T6hPNjc3R Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "985: text: Text: Scalp Trader's recent $DBVT play took off for a +109% gain in just three days. Learn more and #tradesmarter here &gt;&gt;… https://t.co/DdfhnwLak7 Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "986: text: Text: ScalpTrader's recent monster Preferred plays $DCPprB $NGLSprA $TWOprB took off for an average gain of +105% overnig… https://t.co/71rIsHnOfW Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "987: text: Text: Oil majors cut 2020 spending by 22% after prices slump #CNOOC #Stock #MarketScreener https://t.co/clKmFZv2hP https://t.co/JHMTUiqx0U Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "988: text: Text: $QD (+1.8% pre) Qudian Inc. Announces Cancellation of 26,169,241 ADSs Purchased Under Share Repurchase Program, Rep… https://t.co/OgviZEQIos Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "989: text: Text: Europe's LNG imports expected to soar to 100 mln tonnes in 2020 #economy #MarketScreener https://t.co/qHpLYbUTlB https://t.co/MlQzA7HTc3 Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "990: text: Text: ScalpTrader's recent monster Preferred plays $DCPprB $NGLSprA $TWOprB took off for an average gain of +105% overnig… https://t.co/4Tb5q80lMV Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "991: text: Text: $STNE gaps up 20.49% on almost 6x average volume, breaking above 39.45/38.37 handle pivots and through 40.50 second… https://t.co/XRSAgGVE7y Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "992: text: Text: $SPLK gapped up on earnings, up 10.77% on almost 7x average volume. It is coming up near the top of a 38-week long… https://t.co/OPXiKuRLsW Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "993: text: Text: STOCKS NOW: - Dow up 4.73 points  - Nasdaq up 17.91  - S&P up 2.04  Here's what's moving markets:  https://t.co/Yw7HqPotMT Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "994: text: Text: In its 2020 equity outlook, Goldman predicts the S&P 500 will rise by 5% to 3250 in early 2020. \"However, rising po… https://t.co/3e9Zj6q3oQ Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "995: text: Text: $TEVA (+4.8% pre) Teva Pharma (TEVA), Generics Makers Said to be in Talks to End U.S. Probes - Bloomberg  $ENDP… https://t.co/chTtUdguRt Label: 1\n",
            " pred: 0 label: 1\n",
            "\n",
            "996: text: Text: $VCEL - Vericel Corporation: A Must-Have Biotech Post-COVID-19 Sell-Off - Behind The Idea. https://t.co/H2xXFlIJJ7… https://t.co/abHJrHYhFD Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "997: text: Text: RECAP 4/7 -Neg Comments: $JBSS - Sidoti $AAON - Lakewood $FFIN - Lakewood $KNSL - Lakewood $RLI - Lakewood $THFF -… https://t.co/Wfe2aSGUwR Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "998: text: Text: Downgrades 11/25: $AEO $COLM $DGII $EQT $ESS $EVRG $GTT $KRG $MANT $MDCO $NFLX $OMP $PEG $PRU $SBT $SITC $TAP $VIPS Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "999: text: Text: Downgrades 4/7: $MLND $MSGN $MTLS $O $OC $OVV $PEB $PK $PLYA $QEP $RHP $RPAI $SAIA $SDC $SHOP $SKY $SLG $SM $TWLO… https://t.co/NGkYTADOSt Label: 0\n",
            " pred: 0 label: 0\n",
            "\n",
            "Correct: 425 Total: 1000 Accuracy: 0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    # Import the FastLanguageModel from the unsloth library\n",
        "    from unsloth import FastLanguageModel\n",
        "\n",
        "    # Load the pre-trained model and tokenizer\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = saved_name,        # Model name saved in a previous step\n",
        "        max_seq_length = max_seq_length,  # Maximum sequence length for inputs\n",
        "        dtype = dtype,                  # Data type, can be float32, float16, etc.\n",
        "        load_in_4bit = load_in_4bit,    # Whether to load the model in 4-bit precision\n",
        "    )\n",
        "\n",
        "    # Enable fast inference mode for the model, optimizing it for inference speed\n",
        "    FastLanguageModel.for_inference(model)\n"
      ],
      "metadata": {
        "id": "8_UmHEVEH6Dz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model and tokenizer are loaded correctly\n",
        "print(f\"Model: {model}\")\n",
        "print(f\"Tokenizer: {tokenizer}\")\n",
        "\n",
        "# Step 1: Save the model locally\n",
        "local_model_directory = \"model\"  # Specify the directory where to save the model\n",
        "model.save_pretrained(local_model_directory)\n",
        "tokenizer.save_pretrained(local_model_directory)\n",
        "\n",
        "# Step 2: Push to Hugging Face Model Hub\n",
        "huggingface_token = \"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\"  # Replace with your Hugging Face token\n",
        "model_name_on_hub = \"SURESHBEEKHANI/finance_sentiment\"  # Desired model name on Hugging Face\n",
        "\n",
        "# Push the model to Hugging Face Model Hub\n",
        "model.push_to_hub(model_name_on_hub, token=huggingface_token)\n",
        "tokenizer.push_to_hub(model_name_on_hub, token=huggingface_token)\n",
        "\n",
        "print(f\"Model successfully pushed to Hugging Face Model Hub at: {model_name_on_hub}\")\n"
      ],
      "metadata": {
        "id": "em5GNhr7MV1A",
        "outputId": "d9d0ba90-88a4-4192-f4b5-c991afb6557d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aff48c1238de4216aec01307a9ddfe15",
            "66fd6972a0fd434a91547e7911e74ea4",
            "3c59ba5512584c00808517920890a48d",
            "338a6cf0e0b54027a19a73a5e125c41d",
            "6b704816c3a141cbbea40e7fa1b19c9c",
            "04b8a3c5519f406395ec87ebfcad7ddb",
            "8a2267a39fce40b583fee684134c3d9b",
            "ec48f04fd0184d6cb19f23e78e46aaee",
            "9069ad8f76864e6693ee3eed13f13092",
            "a81d7713d74d4afcb30cd6c294005c86",
            "9053acff47d840d7bade20fee5b00d18"
          ]
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): Embedding(128256, 2048)\n",
            "        (layers): ModuleList(\n",
            "          (0-15): 16 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (rotary_emb): LlamaRotaryEmbedding()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Tokenizer: PreTrainedTokenizerFast(name_or_path='unsloth/llama-3.2-1b-bnb-4bit', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|finetune_right_pad_id|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aff48c1238de4216aec01307a9ddfe15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/SURESHBEEKHANI/finance_sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully pushed to Hugging Face Model Hub at: SURESHBEEKHANI/finance_sentiment\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6322d2f463f246be8cbb17ae65e758ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_813b8cef26114e9ba6fb6561dca7986d",
              "IPY_MODEL_db8aa1a95fd446e784ca4d26c1196434",
              "IPY_MODEL_7961bc4d6ccf4bf1ae569a660638ae89"
            ],
            "layout": "IPY_MODEL_ecb6a41d168e48fe8fc3246cb9625c80"
          }
        },
        "813b8cef26114e9ba6fb6561dca7986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf63495a03a340dab1041f573761767d",
            "placeholder": "​",
            "style": "IPY_MODEL_0ab3c939bb5d4c18a783d0d4d1bd6686",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "db8aa1a95fd446e784ca4d26c1196434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cec4c585e6e49c1a0283a970bf48b59",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08c55a05776848a6a11c4b9f91f7eb4e",
            "value": 1000
          }
        },
        "7961bc4d6ccf4bf1ae569a660638ae89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6212cbc05374cb494696fad01563246",
            "placeholder": "​",
            "style": "IPY_MODEL_a005e3e2fdf1478d81b0bf8ae64cd289",
            "value": " 1000/1000 [00:01&lt;00:00, 891.07 examples/s]"
          }
        },
        "ecb6a41d168e48fe8fc3246cb9625c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf63495a03a340dab1041f573761767d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab3c939bb5d4c18a783d0d4d1bd6686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cec4c585e6e49c1a0283a970bf48b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c55a05776848a6a11c4b9f91f7eb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6212cbc05374cb494696fad01563246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a005e3e2fdf1478d81b0bf8ae64cd289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aff48c1238de4216aec01307a9ddfe15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66fd6972a0fd434a91547e7911e74ea4",
              "IPY_MODEL_3c59ba5512584c00808517920890a48d",
              "IPY_MODEL_338a6cf0e0b54027a19a73a5e125c41d"
            ],
            "layout": "IPY_MODEL_6b704816c3a141cbbea40e7fa1b19c9c"
          }
        },
        "66fd6972a0fd434a91547e7911e74ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b8a3c5519f406395ec87ebfcad7ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_8a2267a39fce40b583fee684134c3d9b",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "3c59ba5512584c00808517920890a48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec48f04fd0184d6cb19f23e78e46aaee",
            "max": 45118424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9069ad8f76864e6693ee3eed13f13092",
            "value": 45118424
          }
        },
        "338a6cf0e0b54027a19a73a5e125c41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81d7713d74d4afcb30cd6c294005c86",
            "placeholder": "​",
            "style": "IPY_MODEL_9053acff47d840d7bade20fee5b00d18",
            "value": " 45.1M/45.1M [00:02&lt;00:00, 22.3MB/s]"
          }
        },
        "6b704816c3a141cbbea40e7fa1b19c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b8a3c5519f406395ec87ebfcad7ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2267a39fce40b583fee684134c3d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec48f04fd0184d6cb19f23e78e46aaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9069ad8f76864e6693ee3eed13f13092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a81d7713d74d4afcb30cd6c294005c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9053acff47d840d7bade20fee5b00d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}